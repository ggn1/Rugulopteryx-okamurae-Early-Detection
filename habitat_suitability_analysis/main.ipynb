{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJwa2ernlx97"
      },
      "source": [
        "# Habitat Suitability Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yD5mEgtTkkya",
        "outputId": "e51cf009-e767-4421-97af-da64be845549"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Created folder: /content/bio_oracle/bio_oracle\n",
            "‚úÖ Main Bio-Oracle zip extracted successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Path to target folder\n",
        "folder = \"/content/bio_oracle/bio_oracle\"\n",
        "\n",
        "# üß≠ Step 1: Create the directory if it doesn't exist\n",
        "if not os.path.exists(folder):\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    print(f\"‚úÖ Created folder: {folder}\")\n",
        "else:\n",
        "    print(f\"üìÅ Folder already exists: {folder}\")\n",
        "\n",
        "# üß≠ Step 2: Make sure your Bio-Oracle ZIP file is available in /content\n",
        "biooracle_zip = \"/content/bio_oracle.zip\"\n",
        "\n",
        "if not os.path.exists(biooracle_zip):\n",
        "    print(f\"‚ö†Ô∏è Missing Bio-Oracle archive: {biooracle_zip}\")\n",
        "    print(\"‚û°Ô∏è Please upload 'bio_oracle.zip' to your Colab environment first (using the left file panel).\")\n",
        "else:\n",
        "    # üß≠ Step 3: Extract the main Bio-Oracle zip if not already extracted\n",
        "    with zipfile.ZipFile(biooracle_zip, 'r') as zip_ref:\n",
        "        zip_ref.extractall(folder)\n",
        "    print(\"‚úÖ Main Bio-Oracle zip extracted successfully!\")\n",
        "\n",
        "    # üß≠ Step 4: Extract any internal .zip files inside the folder\n",
        "    for file in os.listdir(folder):\n",
        "        if file.endswith(\".zip\"):\n",
        "            path = os.path.join(folder, file)\n",
        "            with zipfile.ZipFile(path, 'r') as zip_ref:\n",
        "                zip_ref.extractall(folder)\n",
        "            print(\"üì¶ Extracted internal archive:\", file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7rqMsL9mAHQ"
      },
      "source": [
        "****Step 1 ‚Äî Data Collection****\n",
        "\n",
        "Gathered here are 2 key datasets:\n",
        "\n",
        "Species occurrence data\n",
        "\n",
        "Source: GBIF (Global Biodiversity Information Facility)\n",
        "\n",
        "What it contains: Geographic coordinates where Rugulopteryx okamurae has been observed.\n",
        "\n",
        "Each record = presence point (where the species exists).\n",
        "\n",
        "Environmental variables\n",
        "\n",
        "Source: Bio-Oracle marine environmental rasters\n",
        "\n",
        "Variables: temperature, salinity, chlorophyll, oxygen, productivity, and pH\n",
        "\n",
        "Each raster provides global environmental conditions at the sea surface."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsGqt2wGkuIJ",
        "outputId": "1ec99a38-3294-4eb0-f934-422993291876"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-11-06 14:50:06--  https://naturalearth.s3.amazonaws.com/110m_cultural/ne_110m_admin_0_countries.zip\n",
            "Resolving naturalearth.s3.amazonaws.com (naturalearth.s3.amazonaws.com)... 52.92.207.41, 52.92.207.33, 52.92.130.153, ...\n",
            "Connecting to naturalearth.s3.amazonaws.com (naturalearth.s3.amazonaws.com)|52.92.207.41|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 214976 (210K) [application/zip]\n",
            "Saving to: ‚Äòne_110m_admin_0_countries.zip‚Äô\n",
            "\n",
            "ne_110m_admin_0_cou 100%[===================>] 209.94K  1000KB/s    in 0.2s    \n",
            "\n",
            "2025-11-06 14:50:06 (1000 KB/s) - ‚Äòne_110m_admin_0_countries.zip‚Äô saved [214976/214976]\n",
            "\n",
            "Archive:  ne_110m_admin_0_countries.zip\n",
            "  inflating: naturalearth/ne_110m_admin_0_countries.README.html  \n",
            " extracting: naturalearth/ne_110m_admin_0_countries.VERSION.txt  \n",
            " extracting: naturalearth/ne_110m_admin_0_countries.cpg  \n",
            "  inflating: naturalearth/ne_110m_admin_0_countries.dbf  \n",
            "  inflating: naturalearth/ne_110m_admin_0_countries.prj  \n",
            "  inflating: naturalearth/ne_110m_admin_0_countries.shp  \n",
            "  inflating: naturalearth/ne_110m_admin_0_countries.shx  \n"
          ]
        }
      ],
      "source": [
        "!wget https://naturalearth.s3.amazonaws.com/110m_cultural/ne_110m_admin_0_countries.zip -O ne_110m_admin_0_countries.zip\n",
        "!unzip -o ne_110m_admin_0_countries.zip -d naturalearth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeW5cLYykxgS"
      },
      "outputs": [],
      "source": [
        "import geopandas as gpd\n",
        "world = gpd.read_file(\"naturalearth/ne_110m_admin_0_countries.shp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ir5SBwTXkz-L"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def filter_points_within_raster(gdf, raster_path):\n",
        "    \"\"\"Filter GBIF points to those that fall within a raster's extent.\"\"\"\n",
        "    with rasterio.open(raster_path) as src:\n",
        "        minx, miny, maxx, maxy = src.bounds\n",
        "        gdf_filtered = gdf.cx[minx:maxx, miny:maxy]\n",
        "    return gdf_filtered\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqnOY33pbxdK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Path to the folder where all your BioOracle rasters are stored\n",
        "biooracle_dir = \"/content/bio_oracle/bio_oracle\"\n",
        "\n",
        "# List of raster files you want to use (update the names if needed)\n",
        "rasters = {\n",
        "    \"SST_mean\": \"BO_sstmean.tif\",\n",
        "    \"SST_range\": \"BO_sstrange.tif\",\n",
        "    \"Salinity\": \"BO_salinity.tif\",\n",
        "    \"Chlorophyll\": \"BO_chlomean.tif\"\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "5IFSHXfJk5Nh",
        "outputId": "8195ef67-7715-44a5-aeeb-7ffdb88959af"
      },
      "outputs": [],
      "source": [
        "for var, filename in rasters.items():\n",
        "    raster_path = os.path.join(biooracle_dir, filename)\n",
        "    if os.path.exists(raster_path):\n",
        "        try:\n",
        "            gdf_in = filter_points_within_raster(gdf, raster_path)\n",
        "            with rasterio.open(raster_path) as src:\n",
        "                coords = [(x, y) for x, y in zip(gdf_in.geometry.x, gdf_in.geometry.y)]\n",
        "                values = []\n",
        "                for val in src.sample(coords):\n",
        "                    v = val[0]\n",
        "                    if v is not None and not np.isnan(v):\n",
        "                        values.append(float(v))\n",
        "                    else:\n",
        "                        values.append(None)\n",
        "\n",
        "            # Align back to gdf size (NaN for filtered-out points)\n",
        "            extracted_data[var] = [None] * len(gdf)\n",
        "            mask = gdf.index.isin(gdf_in.index)\n",
        "            for i, v in zip(gdf[mask].index, values):\n",
        "                extracted_data[var][i] = v\n",
        "\n",
        "            print(f\"‚úÖ Extracted {sum(pd.notna(values))} valid values for {var}\")\n",
        "            valid_rasters_present = True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error reading raster {filename}: {e}\")\n",
        "            extracted_data[var] = [None] * len(gdf)\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Missing raster: {filename}\")\n",
        "        extracted_data[var] = [None] * len(gdf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZ5OBlVUk7Nj"
      },
      "outputs": [],
      "source": [
        "# -------------------------------------------------------------\n",
        "# üåä VALIDATE COORDINATES WITHIN RASTER EXTENT AND OCEAN MASK\n",
        "# -------------------------------------------------------------\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from rasterio.features import geometry_mask\n",
        "\n",
        "# Load one reference raster (e.g., temperature) to check coverage\n",
        "reference_raster = os.path.join(biooracle_dir, \"Present.Surface.Temperature.Mean.tif\")\n",
        "if os.path.exists(reference_raster):\n",
        "    with rasterio.open(reference_raster) as src:\n",
        "        raster_bounds = src.bounds\n",
        "        print(\"üó∫Ô∏è Raster coverage bounds:\", raster_bounds)\n",
        "\n",
        "        # Filter GBIF points within raster extent\n",
        "        gdf = gdf[\n",
        "            (gdf.geometry.x >= raster_bounds.left) &\n",
        "            (gdf.geometry.x <= raster_bounds.right) &\n",
        "            (gdf.geometry.y >= raster_bounds.bottom) &\n",
        "            (gdf.geometry.y <= raster_bounds.top)\n",
        "        ]\n",
        "\n",
        "        print(f\"‚úÖ Retained {len(gdf)} GBIF points within raster coverage\")\n",
        "\n",
        "        # Optional: derive ocean mask (non-land pixels)\n",
        "        # Any NaN pixel in raster is considered land\n",
        "        coords = [(x, y) for x, y in zip(gdf.geometry.x, gdf.geometry.y)]\n",
        "        values = [v[0] for v in src.sample(coords)]\n",
        "        mask = np.array([not np.isnan(v) for v in values])\n",
        "\n",
        "        gdf = gdf.loc[mask]\n",
        "        print(f\"üåä Retained {len(gdf)} marine GBIF points (inside Bio-Oracle ocean areas)\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Reference raster not found. Skipping spatial validation.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVw_xWBLk_W9"
      },
      "outputs": [],
      "source": [
        "# =============================================================\n",
        "# üåø Early Detection Data Extraction for Rugulopteryx okamurae\n",
        "# =============================================================\n",
        "\n",
        "# Install dependencies (run once in your Colab)\n",
        "!apt-get install -y libgeos-dev\n",
        "!pip install rasterio geopandas seaborn cartopy\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import rasterio\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "from shapely.geometry import Point\n",
        "import requests\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 1Ô∏è‚É£  UNZIP BIO-ORACLE DATA\n",
        "# -------------------------------------------------------------\n",
        "biooracle_zip = \"bio_oracle.zip\"\n",
        "biooracle_dir = \"./bio_oracle/bio_oracle\"\n",
        "\n",
        "if not os.path.exists(biooracle_dir):\n",
        "    os.makedirs(biooracle_dir, exist_ok=True)\n",
        "    if os.path.exists(\"/content/\" + biooracle_zip):\n",
        "        with zipfile.ZipFile(\"/content/\" + biooracle_zip, \"r\") as zip_ref:\n",
        "            zip_ref.extractall(biooracle_dir)\n",
        "        print(\"‚úÖ Bio-Oracle files extracted!\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è {biooracle_zip} not found in /content. Please upload it.\")\n",
        "else:\n",
        "    print(\"‚úÖ Bio-Oracle already extracted.\")\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 2Ô∏è‚É£  LOAD GBIF CSV DATA\n",
        "# -------------------------------------------------------------\n",
        "gbif_file = '/content/gbif_0013072-251025141854904.csv'\n",
        "if not os.path.exists(gbif_file):\n",
        "    gbif_file = '/content/gbif_0013072-251025141854904 (2).csv'  # alternate name if needed\n",
        "\n",
        "if os.path.exists(gbif_file):\n",
        "    df = pd.read_csv(gbif_file, sep='\\t')\n",
        "\n",
        "    # Filter valid coords\n",
        "    df = df.dropna(subset=[\"decimalLatitude\", \"decimalLongitude\"])\n",
        "    df = df[(df[\"decimalLatitude\"].between(-90, 90)) & (df[\"decimalLongitude\"].between(-180, 180))]\n",
        "\n",
        "    print(f\"Loaded {len(df)} Rugulopteryx okamurae records\")\n",
        "\n",
        "    # Convert to GeoDataFrame\n",
        "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.decimalLongitude, df.decimalLatitude), crs=\"EPSG:4326\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è GBIF file not found: {gbif_file}. Please upload the GBIF data.\")\n",
        "    gdf = gpd.GeoDataFrame(columns=['decimalLatitude', 'decimalLongitude', 'geometry'], crs=\"EPSG:4326\")\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# -------------------------------------------------------------\n",
        "# 3Ô∏è‚É£  LOAD RASTERS AND EXTRACT VALUES\n",
        "# -------------------------------------------------------------\n",
        "rasters = {\n",
        "    \"temperature\": \"Present.Surface.Temperature.Mean.tif\",\n",
        "    \"salinity\": \"Present.Surface.Salinity.Mean.tif\",\n",
        "    \"chlorophyll\": \"Present.Surface.Chlorophyll.Mean.tif\",\n",
        "    \"oxygen\": \"Present.Surface.Dissolved.oxygen.Mean.tif\",\n",
        "    \"productivity\": \"Present.Surface.Primary.productivity.Mean.tif\",\n",
        "    \"ph\": \"Present.Surface.pH.BOv2_2.tif\",\n",
        "}\n",
        "\n",
        "extracted_data = {}\n",
        "valid_rasters_present = False\n",
        "\n",
        "for var, filename in rasters.items():\n",
        "    raster_path = os.path.join(biooracle_dir, filename)\n",
        "    if os.path.exists(raster_path):\n",
        "        try:\n",
        "            with rasterio.open(raster_path) as src:\n",
        "                coords = [(x, y) for x, y in zip(gdf.geometry.x, gdf.geometry.y)]\n",
        "                values = [v[0] for v in src.sample(coords)]\n",
        "                extracted_data[var] = values\n",
        "            print(f\"‚úÖ Extracted values for {var}\")\n",
        "            valid_rasters_present = True\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error reading raster {filename}: {e}\")\n",
        "            extracted_data[var] = [None] * len(gdf)\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Missing raster: {filename}\")\n",
        "        extracted_data[var] = [None] * len(gdf)\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 4Ô∏è‚É£  MERGE RESULTS AND CLEAN BIO-ORACLE VALUES\n",
        "# -------------------------------------------------------------\n",
        "if valid_rasters_present:\n",
        "    env_df = pd.DataFrame(extracted_data)\n",
        "    df_reset = df.reset_index(drop=True)\n",
        "    env_df_reset = env_df.reset_index(drop=True)\n",
        "    combined_df = pd.concat([df_reset, env_df_reset], axis=1)\n",
        "\n",
        "    # üßπ Clean invalid raster fill values\n",
        "    import numpy as np\n",
        "    fill_values = [-1.7e308, -3.4e38]\n",
        "    for col in env_df.columns:\n",
        "        combined_df[col] = combined_df[col].replace(fill_values, np.nan)\n",
        "\n",
        "    # Drop rows where all environmental values are NaN\n",
        "    combined_df = combined_df.dropna(subset=env_df.columns, how=\"all\")\n",
        "\n",
        "    print(f\"\\n‚úÖ Combined dataset shape after cleaning: {combined_df.shape}\")\n",
        "    print(combined_df[env_df.columns].describe())\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è No valid rasters found. Cannot create combined dataset.\")\n",
        "    combined_df = df.copy()\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 5Ô∏è‚É£  CORRELATION ANALYSIS\n",
        "# -------------------------------------------------------------\n",
        "if valid_rasters_present and not combined_df.empty:\n",
        "    try:\n",
        "        env_columns_present = [col for col in env_df.columns if col in combined_df.columns]\n",
        "        # Remove constant columns (no variance)\n",
        "        variable_cols = [col for col in env_columns_present if combined_df[col].nunique(dropna=True) > 1]\n",
        "\n",
        "        if variable_cols:\n",
        "            corr_matrix = combined_df[variable_cols].corr()\n",
        "            plt.figure(figsize=(7,6))\n",
        "            sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "            plt.title(\"Correlation between Bio-Oracle environmental variables\")\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"\\n‚ö†Ô∏è No environmental columns with variable data for correlation.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Error during correlation analysis: {e}\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Skipping correlation analysis as environmental data is not available.\")\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 6Ô∏è‚É£  VISUALIZE OCCURRENCES ON MAP WITH CARTOPY\n",
        "# -------------------------------------------------------------\n",
        "if not gdf.empty:\n",
        "    try:\n",
        "        fig = plt.figure(figsize=(12,8))\n",
        "        ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "\n",
        "        # Natural Earth features\n",
        "        ax.add_feature(cfeature.LAND, facecolor='lightgrey')\n",
        "        ax.add_feature(cfeature.OCEAN, facecolor='lightblue')\n",
        "        ax.add_feature(cfeature.COASTLINE)\n",
        "        ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
        "\n",
        "        # Dynamic extent with buffer\n",
        "        buffer = 5  # degrees\n",
        "        minx, miny, maxx, maxy = gdf.total_bounds\n",
        "        ax.set_extent([minx - buffer, maxx + buffer, miny - buffer, maxy + buffer], crs=ccrs.PlateCarree())\n",
        "\n",
        "        # Plot occurrences\n",
        "        ax.scatter(gdf.geometry.x, gdf.geometry.y,\n",
        "                   color='darkred', s=20, alpha=0.7,\n",
        "                   transform=ccrs.PlateCarree(),\n",
        "                   label='Rugulopteryx okamurae')\n",
        "\n",
        "        plt.title(\"üåä Rugulopteryx okamurae Occurrences (GBIF)\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Error visualizing occurrences on map with Cartopy: {e}\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Skipping map visualization as no valid GBIF data was loaded.\")\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 7Ô∏è‚É£  SAVE RESULTS\n",
        "# -------------------------------------------------------------\n",
        "if not combined_df.empty:\n",
        "    try:\n",
        "        combined_df.to_csv(\"Rugulopteryx_environmental_data.csv\", index=False)\n",
        "        print(\"\\n‚úÖ Saved final dataset as 'Rugulopteryx_environmental_data.csv'\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Error saving combined dataset: {e}\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Skipping saving combined dataset as it is empty.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDxl8q9RlB-Q"
      },
      "outputs": [],
      "source": [
        "# -------------------------------------------------------------\n",
        "# 5Ô∏è‚É£b  CORRELATION WITH LATITUDE, LONGITUDE & PRESENCE\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "# Add presence column (all ones for current GBIF data)\n",
        "# If later you include absence/background points, you can set 0 for absences.\n",
        "combined_df[\"presence\"] = 1\n",
        "\n",
        "# Select variables for correlation\n",
        "geo_env_cols = [\"decimalLatitude\", \"decimalLongitude\", \"presence\",\n",
        "                \"temperature\", \"salinity\", \"chlorophyll\", \"oxygen\", \"productivity\", \"ph\"]\n",
        "\n",
        "# Keep only columns that actually exist\n",
        "geo_env_cols = [col for col in geo_env_cols if col in combined_df.columns]\n",
        "\n",
        "# Drop rows with NaN\n",
        "geo_env_data = combined_df[geo_env_cols].dropna()\n",
        "\n",
        "if len(geo_env_data) > 1:\n",
        "    corr_geo_env = geo_env_data.corr()\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(corr_geo_env, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "    plt.title(\"Correlation between Latitude, Longitude, Presence and Bio-Oracle Variables\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Not enough valid data to compute extended correlation matrix.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWY6QhpUmUk3"
      },
      "source": [
        "****‚öôÔ∏è Step 2 ‚Äî Generating Pseudo-Absences****\n",
        "\n",
        "Since you only had presence data, you added pseudo-absence points randomly distributed across the ocean (500 in your case).\n",
        "\n",
        "Why?\n",
        "To contrast conditions where the species is known not to occur (or is unlikely).\n",
        "This is standard in SDM when absence data is unavailable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DC7Oxr4ilE_Q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from shapely.geometry import Point\n",
        "\n",
        "# Create 500 pseudo-absence points randomly across raster extent\n",
        "with rasterio.open(os.path.join(biooracle_dir, \"Present.Surface.Temperature.Mean.tif\")) as src:\n",
        "    minx, miny, maxx, maxy = src.bounds\n",
        "    np.random.seed(42)\n",
        "    rand_lon = np.random.uniform(minx, maxx, 500)\n",
        "    rand_lat = np.random.uniform(miny, maxy, 500)\n",
        "    abs_df = pd.DataFrame({\"decimalLongitude\": rand_lon, \"decimalLatitude\": rand_lat, \"presence\": 0})\n",
        "    abs_gdf = gpd.GeoDataFrame(abs_df, geometry=gpd.points_from_xy(rand_lon, rand_lat), crs=\"EPSG:4326\")\n",
        "\n",
        "# Combine with presence data\n",
        "presence_df = combined_df.copy()\n",
        "presence_df[\"presence\"] = 1\n",
        "merged_data = pd.concat([presence_df, abs_gdf], ignore_index=True)\n",
        "# -------------------------------------------------------------\n",
        "# EXTRACT BIO-ORACLE VALUES FOR ALL POINTS (presence + absence)\n",
        "# -------------------------------------------------------------\n",
        "coords = list(zip(merged_data[\"decimalLongitude\"], merged_data[\"decimalLatitude\"]))\n",
        "\n",
        "env_vars = [\"temperature\", \"salinity\", \"chlorophyll\", \"oxygen\", \"productivity\", \"ph\"]\n",
        "raster_paths = {\n",
        "    \"temperature\": os.path.join(biooracle_dir, \"Present.Surface.Temperature.Mean.tif\"),\n",
        "    \"salinity\": os.path.join(biooracle_dir, \"Present.Surface.Salinity.Mean.tif\"),\n",
        "    \"chlorophyll\": os.path.join(biooracle_dir, \"Present.Surface.Chlorophyll.Mean.tif\"),\n",
        "    \"oxygen\": os.path.join(biooracle_dir, \"Present.Surface.Dissolved.oxygen.Mean.tif\"),\n",
        "    \"productivity\": os.path.join(biooracle_dir, \"Present.Surface.Primary.productivity.Mean.tif\"),\n",
        "    \"ph\": os.path.join(biooracle_dir, \"Present.Surface.pH.BOv2_2.tif\"),\n",
        "}\n",
        "\n",
        "for var in env_vars:\n",
        "    with rasterio.open(raster_paths[var]) as src:\n",
        "        merged_data[var] = [v[0] for v in src.sample(coords)]\n",
        "\n",
        "# Clean fill values (Bio-Oracle missing data codes)\n",
        "fill_values = [-1.7e308, -3.4e38]\n",
        "merged_data.replace(fill_values, np.nan, inplace=True)\n",
        "\n",
        "# Drop rows where all environmental variables are NaN\n",
        "merged_data.dropna(subset=env_vars, how=\"all\", inplace=True)\n",
        "\n",
        "print(f\"‚úÖ Extracted environmental data for {len(merged_data)} presence/absence points\")\n",
        "corr_vars = [\"decimalLatitude\", \"decimalLongitude\", \"presence\"] + env_vars\n",
        "corr_matrix = merged_data[corr_vars].corr()\n",
        "\n",
        "plt.figure(figsize=(9,7))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "plt.title(\"Correlation between Latitude, Longitude, Presence and Bio-Oracle Variables\")\n",
        "plt.show()\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "features = env_vars\n",
        "merged_clean = merged_data.dropna(subset=features + [\"presence\"])\n",
        "X = merged_clean[features]\n",
        "y = merged_clean[\"presence\"]\n",
        "\n",
        "# Standardize predictors\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Fit logistic regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_scaled, y)\n",
        "\n",
        "# Show variable importance\n",
        "coeffs = pd.DataFrame({\n",
        "    \"Variable\": features,\n",
        "    \"Coefficient\": model.coef_[0]\n",
        "}).sort_values(\"Coefficient\", ascending=False)\n",
        "\n",
        "print(\"\\nüåø Environmental influence on presence probability:\")\n",
        "print(coeffs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjZIgjcRmemx"
      },
      "source": [
        "****Step 3 ‚Äî Statistical Model: Logistic Regression****\n",
        "\n",
        "This is the model you used to predict suitability.\n",
        "\n",
        "Why Logistic Regression?\n",
        "\n",
        "It‚Äôs a classic, interpretable binary classification model.\n",
        "\n",
        "It estimates the probability that a given environment is ‚Äúsuitable‚Äù (i.e., presence = 1).\n",
        "\n",
        "It‚Äôs mathematically equivalent to the ‚ÄúGLM‚Äù (Generalized Linear Model) used in many ecological studies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j11G2d9DlH0F"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define variables\n",
        "env_vars = [\"temperature\", \"salinity\", \"chlorophyll\", \"oxygen\", \"productivity\", \"ph\"]\n",
        "\n",
        "# Drop missing rows\n",
        "merged_clean = merged_data.dropna(subset=env_vars + [\"presence\"])\n",
        "\n",
        "X = merged_clean[env_vars]\n",
        "y = merged_clean[\"presence\"]\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Fit logistic regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_scaled, y)\n",
        "\n",
        "# Predict probability of presence\n",
        "merged_clean[\"suitability\"] = model.predict_proba(X_scaled)[:, 1]\n",
        "\n",
        "print(\"‚úÖ Habitat suitability scores calculated!\")\n",
        "merged_clean[[\"decimalLongitude\", \"decimalLatitude\", \"presence\", \"suitability\"]].head()\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "\n",
        "# Create figure\n",
        "fig = plt.figure(figsize=(14,8))\n",
        "ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "\n",
        "# Add base map features\n",
        "ax.add_feature(cfeature.LAND, facecolor='lightgrey')\n",
        "ax.add_feature(cfeature.OCEAN, facecolor='lightblue')\n",
        "ax.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
        "ax.add_feature(cfeature.BORDERS, linestyle=':', linewidth=0.5)\n",
        "\n",
        "# Add gridlines\n",
        "ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False)\n",
        "\n",
        "# Plot suitable areas\n",
        "high = merged_clean[merged_clean[\"suitability\"] > 0.5]\n",
        "low = merged_clean[merged_clean[\"suitability\"] <= 0.5]\n",
        "\n",
        "ax.scatter(low[\"decimalLongitude\"], low[\"decimalLatitude\"],\n",
        "           color=\"red\", s=20, alpha=0.5, label=\"Unsuitable (<0.5)\", transform=ccrs.PlateCarree())\n",
        "ax.scatter(high[\"decimalLongitude\"], high[\"decimalLatitude\"],\n",
        "           color=\"green\", s=25, alpha=0.7, label=\"Suitable (>0.5)\", transform=ccrs.PlateCarree())\n",
        "\n",
        "plt.title(\"üåä Environmental Suitability for Rugulopteryx okamurae\", fontsize=14)\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.show()\n",
        "plt.figure(figsize=(14,8))\n",
        "ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "\n",
        "ax.add_feature(cfeature.LAND, facecolor='lightgrey')\n",
        "ax.add_feature(cfeature.OCEAN, facecolor='lightblue')\n",
        "ax.add_feature(cfeature.COASTLINE)\n",
        "\n",
        "sc = ax.scatter(\n",
        "    merged_clean[\"decimalLongitude\"],\n",
        "    merged_clean[\"decimalLatitude\"],\n",
        "    c=merged_clean[\"suitability\"],\n",
        "    cmap=\"viridis\",\n",
        "    s=25,\n",
        "    alpha=0.8,\n",
        "    transform=ccrs.PlateCarree()\n",
        ")\n",
        "\n",
        "plt.colorbar(sc, label=\"Suitability probability (0‚Äì1)\", orientation=\"vertical\")\n",
        "plt.title(\"Predicted Habitat Suitability for Rugulopteryx okamurae\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Zl_6Q0bmq6R"
      },
      "source": [
        "****üåç Step 6 ‚Äî Ecological Interpretation****\n",
        "\n",
        "The map highlights regions where the combination of environmental variables (temperature, salinity, etc.) are most similar to the conditions of known Rugulopteryx okamurae populations.\n",
        "\n",
        "These areas are considered potentially suitable ‚Äî meaning, if the algae were introduced there, conditions might allow it to establish.\n",
        "\n",
        "Unsuitable areas represent environmental mismatches, where the algae likely cannot survive or reproduce effectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYTblXWXaHIO"
      },
      "outputs": [],
      "source": [
        "# -------------------------------------------------------------\n",
        "# ‚úÖ  MODEL EVALUATION: ACCURACY, CONFUSION MATRIX, ROC CURVE\n",
        "# -------------------------------------------------------------\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Predict binary presence/absence (threshold 0.5)\n",
        "y_pred = (model.predict_proba(X_scaled)[:, 1] >= 0.5).astype(int)\n",
        "y_true = y\n",
        "\n",
        "# 1Ô∏è‚É£ Accuracy\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print(f\"‚úÖ Model accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# 2Ô∏è‚É£ Confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"\\nüìä Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# 3Ô∏è‚É£ Classification report (precision, recall, F1-score)\n",
        "print(\"\\nüìã Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, digits=2))\n",
        "\n",
        "# 4Ô∏è‚É£ ROC curve and AUC\n",
        "y_proba = model.predict_proba(X_scaled)[:, 1]\n",
        "auc = roc_auc_score(y_true, y_proba)\n",
        "fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(fpr, tpr, label=f\"AUC = {auc:.2f}\", color='darkorange')\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='grey')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Habitat Suitability Model')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
